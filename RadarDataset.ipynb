{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNm8YCf63HiA0RInbc1Uo9g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liavaldetaro/RadarDataset/blob/main/RadarDataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Radar dataset**\n",
        "\n",
        "In this notebook, we will explore a radar dataset from Kaggle: https://www.kaggle.com/datasets/iroldan/real-doppler-raddar-database\n",
        "\n",
        "\n",
        "> The radar used to capture the data is a ubiquitous or persistent radar system developed by the Microwave and Radar Group from the UPM called RAD-DAR (Digital Array Receiver). The radar uses a frequency-modulated continuous wave (FMCW) on a frequency band centered at 8.75 GHz with a maximum bandwidth of 500 MHz.\n",
        "\n",
        "The data contains **labelled** video radar data from cars, people and drones. Let's try to see if we can classify it!\n",
        "\n"
      ],
      "metadata": {
        "id": "2ervrwGI2-re"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "HnFdD5Or2hHS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from collections.abc import Iterator\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import EarlyStopping\n",
        "import kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Let's start by downloading the dataset into our notebook:\n",
        "path = kagglehub.dataset_download(\"iroldan/real-doppler-raddar-database\")\n",
        "\n",
        "# Let's print the path to where the data is saved to:\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpbNfl1J6B9-",
        "outputId": "f94fdc75-7d3f-48e7-dee8-69a2dce0961e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/iroldan/real-doppler-raddar-database?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63.6M/63.6M [00:00<00:00, 247MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/iroldan/real-doppler-raddar-database/versions/2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data analysis**\n",
        "\n",
        "Perfect! Our data is loaded into the .cache folder. Let's start by taking a look at what the data looks like."
      ],
      "metadata": {
        "id": "mjrCxwRbfw75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see what is in our dataset\n",
        "\n",
        "print(os.listdir(path))   # listing the subdirectories\n",
        "print(os.listdir(path + '/data/Cars/15-42'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ejYBSHGKz6u",
        "outputId": "1f03f68a-27d2-4d8b-85e1-e143aafd4112"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Cars', 'People', 'Drones', 'data']\n",
            "['159.csv', '145.csv', '014.csv', '161.csv', '114.csv', '117.csv', '177.csv', '024.csv', '127.csv', '008.csv', '031.csv', '172.csv', '079.csv', '148.csv', '053.csv', '022.csv', '166.csv', '185.csv', '151.csv', '162.csv', '057.csv', '110.csv', '062.csv', '030.csv', '153.csv', '064.csv', '167.csv', '065.csv', '135.csv', '126.csv', '072.csv', '131.csv', '140.csv', '012.csv', '134.csv', '103.csv', '099.csv', '035.csv', '094.csv', '184.csv', '119.csv', '092.csv', '154.csv', '138.csv', '011.csv', '082.csv', '130.csv', '123.csv', '168.csv', '112.csv', '096.csv', '163.csv', '105.csv', '088.csv', '152.csv', '029.csv', '021.csv', '002.csv', '005.csv', '136.csv', '048.csv', '017.csv', '104.csv', '070.csv', '142.csv', '038.csv', '078.csv', '118.csv', '086.csv', '125.csv', '128.csv', '068.csv', '087.csv', '001.csv', '150.csv', '077.csv', '007.csv', '003.csv', '052.csv', '066.csv', '054.csv', '013.csv', '028.csv', '097.csv', '033.csv', '178.csv', '063.csv', '141.csv', '040.csv', '156.csv', '129.csv', '019.csv', '139.csv', '101.csv', '045.csv', '036.csv', '020.csv', '089.csv', '083.csv', '133.csv', '093.csv', '056.csv', '018.csv', '061.csv', '047.csv', '173.csv', '169.csv', '081.csv', '157.csv', '179.csv', '055.csv', '158.csv', '049.csv', '084.csv', '090.csv', '108.csv', '074.csv', '107.csv', '176.csv', '165.csv', '046.csv', '037.csv', '122.csv', '050.csv', '106.csv', '027.csv', '171.csv', '069.csv', '183.csv', '059.csv', '155.csv', '080.csv', '095.csv', '058.csv', '143.csv', '075.csv', '091.csv', '043.csv', '181.csv', '111.csv', '170.csv', '015.csv', '085.csv', '041.csv', '147.csv', '137.csv', '164.csv', '073.csv', '113.csv', '175.csv', '160.csv', '051.csv', '186.csv', '010.csv', '174.csv', '025.csv', '116.csv', '067.csv', '042.csv', '149.csv', '032.csv', '100.csv', '109.csv', '076.csv', '120.csv', '016.csv', '060.csv', '182.csv', '132.csv', '044.csv', '121.csv', '146.csv', '009.csv', '115.csv', '098.csv', '034.csv', '039.csv', '004.csv', '006.csv', '026.csv', '124.csv', '023.csv', '180.csv', '071.csv', '102.csv', '144.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's open an image from each dataset\n",
        "\n",
        "drone_image = pd.read_csv(\n",
        "    path + \"/Drones/15-42/159.csv\"\n",
        ")\n",
        "\n",
        "car_image = pd.read_csv(\n",
        "    path + \"/Cars/15-42/159.csv\"\n",
        ")\n",
        "\n",
        "people_image = pd.read_csv(\n",
        "    path + \"/People/16-06/014.csv\"\n",
        ")\n",
        "\n",
        "\n",
        "# We can now plot the images\n",
        "fig, ax = plt.subplots(3, 1, figsize=(5,15))\n",
        "plt1 = ax[0].imshow(drone_image, cmap='plasma', vmax=-75)\n",
        "plt2 = ax[1].imshow(car_image, cmap='plasma', vmax=-75)\n",
        "plt3 = ax[2].imshow(people_image, cmap='plasma', vmax=-75)\n",
        "ax[0].set_title(\"Drone\")\n",
        "ax[1].set_title(\"Car\")\n",
        "ax[2].set_title(\"People\")\n",
        "plt.colorbar(plt1, ax=ax[0], fraction=0.01, pad=0.04)\n",
        "plt.colorbar(plt2, ax=ax[1], fraction=0.01, pad=0.04)\n",
        "plt.colorbar(plt3, ax=ax[2], fraction=0.01, pad=0.04)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PDZqwg5XgAJb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "fd69c4fa-18ac-4641-c660-8749705622c5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3075248076.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Let's open an image from each dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m drone_image = pd.read_csv(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/Drones/15-42/159.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The images don't really look that different to the human eye - let's hope our model can do a better job at classifying them :)"
      ],
      "metadata": {
        "id": "DjBtouShOsDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we are a bit more familiar with the data, we can start **preparing it** to feed into our AI model.\n",
        "There are a couple of steps to this preparation:\n",
        "\n",
        "1.  Load in the images and corresponding labels (if it is a car, a drone or a person)\n",
        "2.  Normalize our data - meaning that we change the values so that all of the pixels are between 0 and 1 - this makes it easier for our AI model.\n",
        "3. Split our data into a training set (which we give to the model) and a test set (which the model doesn't get to see - we use this set to test how good our model is).\n",
        "\n",
        "\n",
        "To keep our code organized, let's put these functionalities into **python functions**. Don't worry too much about this part of the code - the fun AI training comes later :)\n",
        "\n"
      ],
      "metadata": {
        "id": "xhwot8cBWnka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = {\"Cars\": 0, \"Drones\": 1, \"People\": 2}\n",
        "\n",
        "\n",
        "def load_category_frames(folder_path):\n",
        "  \"\"\"Load all CSVs from a folder in order.\"\"\"\n",
        "  frames = []\n",
        "  files = sorted(\n",
        "      [f for f in os.listdir(folder_path) if f.endswith(\".csv\")],\n",
        "      key=lambda x: int(x.split('_')[-1].split('.')[0])\n",
        "  )\n",
        "  for file in files:\n",
        "      file_path = os.path.join(folder_path, file)\n",
        "      df = pd.read_csv(file_path, header=None).values\n",
        "      frames.append(df)\n",
        "  return frames\n",
        "\n",
        "\n",
        "def data_preparation(\n",
        "    dataset_path:str, categories: dict, test_size: float, random_seed: int\n",
        "    ) -> tuple[tf.data.Dataset, tf.data.Dataset, tf.data.Dataset, tf.data.Dataset]:\n",
        "    \"\"\"Crawls through our data folder, normalizes all images and returns our\n",
        "    split dataset.\"\"\"\n",
        "\n",
        "    # Crawl through the source directory\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "      print(dirs, files)\n",
        "\n"
      ],
      "metadata": {
        "id": "eiCNqb9tYCX1"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames = load_category_frames(path + \"/Cars/15-42\")\n",
        "\n",
        "print(np.array(frames).shape)"
      ],
      "metadata": {
        "id": "gDVnVTshYB79",
        "outputId": "677a5414-cf7c-4093-f4d5-8bcaf6569b7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['001.csv', '002.csv', '003.csv', '004.csv', '005.csv', '006.csv', '007.csv', '008.csv', '009.csv', '010.csv', '011.csv', '012.csv', '013.csv', '014.csv', '015.csv', '016.csv', '017.csv', '018.csv', '019.csv', '020.csv', '021.csv', '022.csv', '023.csv', '024.csv', '025.csv', '026.csv', '027.csv', '028.csv', '029.csv', '030.csv', '031.csv', '032.csv', '033.csv', '034.csv', '035.csv', '036.csv', '037.csv', '038.csv', '039.csv', '040.csv', '041.csv', '042.csv', '043.csv', '044.csv', '045.csv', '046.csv', '047.csv', '048.csv', '049.csv', '050.csv', '051.csv', '052.csv', '053.csv', '054.csv', '055.csv', '056.csv', '057.csv', '058.csv', '059.csv', '060.csv', '061.csv', '062.csv', '063.csv', '064.csv', '065.csv', '066.csv', '067.csv', '068.csv', '069.csv', '070.csv', '071.csv', '072.csv', '073.csv', '074.csv', '075.csv', '076.csv', '077.csv', '078.csv', '079.csv', '080.csv', '081.csv', '082.csv', '083.csv', '084.csv', '085.csv', '086.csv', '087.csv', '088.csv', '089.csv', '090.csv', '091.csv', '092.csv', '093.csv', '094.csv', '095.csv', '096.csv', '097.csv', '098.csv', '099.csv', '100.csv', '101.csv', '102.csv', '103.csv', '104.csv', '105.csv', '106.csv', '107.csv', '108.csv', '109.csv', '110.csv', '111.csv', '112.csv', '113.csv', '114.csv', '115.csv', '116.csv', '117.csv', '118.csv', '119.csv', '120.csv', '121.csv', '122.csv', '123.csv', '124.csv', '125.csv', '126.csv', '127.csv', '128.csv', '129.csv', '130.csv', '131.csv', '132.csv', '133.csv', '134.csv', '135.csv', '136.csv', '137.csv', '138.csv', '139.csv', '140.csv', '141.csv', '142.csv', '143.csv', '144.csv', '145.csv', '146.csv', '147.csv', '148.csv', '149.csv', '150.csv', '151.csv', '152.csv', '153.csv', '154.csv', '155.csv', '156.csv', '157.csv', '158.csv', '159.csv', '160.csv', '161.csv', '162.csv', '163.csv', '164.csv', '165.csv', '166.csv', '167.csv', '168.csv', '169.csv', '170.csv', '171.csv', '172.csv', '173.csv', '174.csv', '175.csv', '176.csv', '177.csv', '178.csv', '179.csv', '180.csv', '181.csv', '182.csv', '183.csv', '184.csv', '185.csv', '186.csv']\n",
            "(186, 11, 61)\n"
          ]
        }
      ]
    }
  ]
}